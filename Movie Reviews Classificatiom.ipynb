{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a789fe",
   "metadata": {},
   "source": [
    "# Task-Movie Reviews Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317657e",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33cf25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eac13b",
   "metadata": {},
   "source": [
    "# load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7185cb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('IMDB Dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac35afda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186de63",
   "metadata": {},
   "source": [
    "# sentiment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b58817b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "negative    25000\n",
       "positive    25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77154da7",
   "metadata": {},
   "source": [
    "# Text Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1223c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numeric characters, and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # Remove extra white space\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Removing stopwords and applying stemming\n",
    "    words = [ps.stem(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88839b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text preprocessing to a 'review' column \n",
    "data['review'] = data['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d10b8d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch oz episod hook right ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one review mention watch oz episod hook right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product br br film techniqu unass...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonder littl product br br film techniqu unass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movi right good job creativ origin fir...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought movi right good job creativ origin fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogu bad act idiot direct anno...</td>\n",
       "      <td>negative</td>\n",
       "      <td>bad plot bad dialogu bad act idiot direct anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>cathol taught parochi elementari school nun ta...</td>\n",
       "      <td>negative</td>\n",
       "      <td>cathol taught parochi elementari school nun ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>go disagre previou comment side maltin one sec...</td>\n",
       "      <td>negative</td>\n",
       "      <td>go disagr previou comment side maltin one seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expect star trek movi high art fan expect ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>one expect star trek movi high art fan expect ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      one review mention watch oz episod hook right ...  positive   \n",
       "1      wonder littl product br br film techniqu unass...  positive   \n",
       "2      thought wonder way spend time hot summer weeke...  positive   \n",
       "3      basic famili littl boy jake think zombi closet...  negative   \n",
       "4      petter mattei love time money visual stun film...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  thought movi right good job creativ origin fir...  positive   \n",
       "49996  bad plot bad dialogu bad act idiot direct anno...  negative   \n",
       "49997  cathol taught parochi elementari school nun ta...  negative   \n",
       "49998  go disagre previou comment side maltin one sec...  negative   \n",
       "49999  one expect star trek movi high art fan expect ...  negative   \n",
       "\n",
       "                                     review_preprocessed  \n",
       "0      one review mention watch oz episod hook right ...  \n",
       "1      wonder littl product br br film techniqu unass...  \n",
       "2      thought wonder way spend time hot summer weeke...  \n",
       "3      basic famili littl boy jake think zombi closet...  \n",
       "4      petter mattei love time money visual stun film...  \n",
       "...                                                  ...  \n",
       "49995  thought movi right good job creativ origin fir...  \n",
       "49996  bad plot bad dialogu bad act idiot direct anno...  \n",
       "49997  cathol taught parochi elementari school nun ta...  \n",
       "49998  go disagr previou comment side maltin one seco...  \n",
       "49999  one expect star trek movi high art fan expect ...  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review_preprocessed']=data['review'].apply(preprocess_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f7befe",
   "metadata": {},
   "source": [
    "# features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee233c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, 0]\n",
    "y = data.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee9879",
   "metadata": {},
   "source": [
    "# dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf23b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a0a2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c022bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf=Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5bb52b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b925846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=text_clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c41368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c0d9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5569  722]\n",
      " [ 635 5574]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6727e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89      6291\n",
      "    positive       0.89      0.90      0.89      6209\n",
      "\n",
      "    accuracy                           0.89     12500\n",
      "   macro avg       0.89      0.89      0.89     12500\n",
      "weighted avg       0.89      0.89      0.89     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e166dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89144\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecfc9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e0d349",
   "metadata": {},
   "source": [
    "# Encode labels: 'positive' as 1, 'negative' as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "167323f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.apply(lambda x: 1 if x == 'positive' else 0)\n",
    "test_y = test_y.apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc989097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to sequences of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "max_sequence_length = 100  # Choose an appropriate sequence length\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c2be4",
   "metadata": {},
   "source": [
    "# Build the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5720db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_sequence_length))\n",
    "\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Use 'sigmoid' for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c9c9f",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3890484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c4b8840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 136s 280ms/step - loss: 0.3629 - accuracy: 0.8367 - val_loss: 0.2882 - val_accuracy: 0.8796\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.1897 - accuracy: 0.9286 - val_loss: 0.3029 - val_accuracy: 0.8764\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 130s 277ms/step - loss: 0.1142 - accuracy: 0.9599 - val_loss: 0.4026 - val_accuracy: 0.8660\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 130s 276ms/step - loss: 0.0725 - accuracy: 0.9749 - val_loss: 0.4522 - val_accuracy: 0.8669\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 130s 278ms/step - loss: 0.0480 - accuracy: 0.9839 - val_loss: 0.6005 - val_accuracy: 0.8612\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 130s 276ms/step - loss: 0.0361 - accuracy: 0.9889 - val_loss: 0.6947 - val_accuracy: 0.8589\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 130s 277ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 0.6468 - val_accuracy: 0.8569\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 130s 278ms/step - loss: 0.0236 - accuracy: 0.9930 - val_loss: 0.6844 - val_accuracy: 0.8597\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 130s 277ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.6838 - val_accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 131s 279ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.9086 - val_accuracy: 0.8525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2115847ce50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_sequences, train_y, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "286f2d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 0.9492 - accuracy: 0.8497\n",
      "Test Loss: 0.9492, Test Accuracy: 84.97%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_sequences, test_y)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77669fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step\n",
      "Confusion Matrix:\n",
      "[[5134 1157]\n",
      " [ 722 5487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_sequences)\n",
    "\n",
    "# Convert predicted probabilities to binary labels\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "confusion_mat = confusion_matrix(test_y, predicted_labels)\n",
    "class_report = classification_report(test_y, predicted_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c255c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      6291\n",
      "           1       0.83      0.88      0.85      6209\n",
      "\n",
      "    accuracy                           0.85     12500\n",
      "   macro avg       0.85      0.85      0.85     12500\n",
      "weighted avg       0.85      0.85      0.85     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "446f978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"movie-review.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf6807",
   "metadata": {},
   "source": [
    "# model testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee4b6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=[\"I can't believe I spent money to watch this film.\"\n",
    "         \"It was a never-ending series of clichÃ©s, and the ending was so predictable.\" \n",
    "         \"I expected more from the talented cast, but they couldn't save this disaster of a movie.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e138182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "\n",
    "# Fit the CountVectorizer on your training data and transform the data\n",
    "review= cv.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d8ab4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 for positive review and 0 for negative review\n"
     ]
    }
   ],
   "source": [
    "print(\"1 for positive review and 0 for negative review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5da96d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Review 1: I can't believe I spent money to watch this  film.It was a never-ending series of clichÃ©s, and the ending was so predictable.I expected more from the talented cast, but they couldn't save this disaster of a movie.\n",
      "Predicted Sentiment: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assuming you have already loaded and preprocessed your training data and model\n",
    "# tokenizer should be the same one used during training\n",
    "# max_sequence_length should match the expected input length of your model\n",
    "\n",
    "# Define the review text\n",
    "reviews = [\n",
    "    \"I can't believe I spent money to watch this  film.It was a never-ending series of clichÃ©s, and the ending was so predictable.I expected more from the talented cast, but they couldn't save this disaster of a movie.\"\n",
    "]\n",
    "\n",
    "# Tokenize and pad the review text\n",
    "review_sequences = tokenizer.texts_to_sequences(reviews)\n",
    "review_sequences_padded = pad_sequences(review_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert the padded sequences to a dense NumPy array\n",
    "review_data = np.array(review_sequences_padded)\n",
    "\n",
    "# Make predictions on the review data\n",
    "predictions = model.predict(review_data)\n",
    "\n",
    "# Interpret the predictions\n",
    "for i, prediction in enumerate(predictions):\n",
    "    sentiment = \"positive\" if prediction > 0.5 else \"negative\"\n",
    "    print(f\"Review {i+1}: {reviews[i]}\\nPredicted Sentiment: {sentiment}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
